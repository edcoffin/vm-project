\section{Results}
\label{sec:results}
\subsection{Compilation Time}
The first question we looked at was how long each framework took to compile a function. 
This time includes running the program from start to finish and includes the setup and teardown time of the JIT.
Each program was executed 20 times.

In Table \ref{tab:compile_time} we see that for the increment task JitBuilder compiled the function 61.5\% faster than MCJIT.
Looking into this further, the initial run to compile the function was roughly 900,000 nanoseconds.
Repeated executions made by our benchmarking framework\cite{googleBench} were closer to 500,000 nanoseconds as the instructions for this relatively small example were likely be cached.
For the other two tasks, we see that MCJIT was able to compile the functions more quickly than JitBuilder (recursive-fib compiled 16.5\% faster, and iterative-fib compiled 40.1\% faster ).


\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|}
  \hline
  \multicolumn{1}{|l|}
  {\multirow{2}{*}{}} 
  & \multicolumn{3}{c|}{\textbf{LLVM MCJIT}}                                                                                                     & \multicolumn{3}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                              \\ \cline{2-7}
  
  \multicolumn{1}{|c|}{\textbf{Program}}
  & \multicolumn{1}{c|}{mean (ns)}  
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}     
  & \multicolumn{1}{c|}{mean (ns)}           
  & \multicolumn{1}{c|}{median} 
  & \multicolumn{1}{c|}{std. dev.}             
  \\ \hline
  
  increment                               
  & \num{1378060} %llvm                            
  & \num{1387338}                
  & \num{39774}               
  & \num{536741}  %jitbuilder                           
  & \num{537103}                
  & \num{2620}                                 
  \\ \hline
  
  recursive-fib                           
  & \num{1548316} %llvm                           
  & \num{1547491}                
  & \num{3925}                
  & \num{1854393} %jitbuilder                           
  & \num{1850322}               
  & \num{21754}
  \\ \hline
  
  iterative-fib                           
  & \num{2509502} %llvm                           
  & \num{2519808}                
  & \num{60429}              
  & \num{4192213} %jitbuilder                           
  & \num{4191730}               
  & \num{10419}                                
  \\ \hline
  
\end{tabular}
  \caption{Results of compiling each function 20 times with each JIT framework.}
  \label{tab:compile_time}
\end{table*}


% Increment IR generation for JitBuilder
\begin{lstlisting}[float,floatplacement=H,
  caption={Generating JitBuilder IR for the increment program.},
  label=lst:jitbuilder_increment]
bool IncrementMethod::buildIL()
{
  Return(
    Add(
        Load("value"),
        ConstInt32(1)));
  return true;
}
\end{lstlisting}

% IR code for LLVM increment
\begin{lstlisting}[float,floatplacement=H,
  caption={Generating MCJIT IR for the increment program.},
  label=lst:llvm_increment]
static Function *CreateIncrementFunction(
                  Module *M, 
                  LLVMContext &c) {
  FunctionType *f = FunctionType::get(Type::getInt32Ty(c), 
                      {Type::getInt32Ty(c)}, 
                      false);
  
  Function *incrementF = Function::Create(f, 
                      Function::ExternalLinkage, 
                      "increment", 
                      M);

  BasicBlock *BB = BasicBlock::Create(c, 
                      "EntryBlock", 
                      incrementF);
  
  Value *One = ConstantInt::get(Type::getInt32Ty(c), 1);
  
  Argument *ArgX = &*incrementF->arg_begin(); 
  ArgX->setName("AnArg");

  Value *Sum = BinaryOperator::CreateAdd(ArgX, 
                                One,
                                "addresult", 
                                BB);

  ReturnInst::Create(c, Sum, BB);
  return incrementF;
}
\end{lstlisting}

\subsection{Execution Time}
With JIT compilation completed, we turn to measuring how much CPU time is spent actually executing the function.
To measure this, we compiled the function once and then executed the compiled function 1000 times.
For each program, the process was repeated 20 times (see Table \ref{tab:1k_time_with_one_compile}).
Aside from the increment program, which favoured JitBuilder, both the recursive and iterative fib functions executed more quickly with LLVM generated code (0.53\% faster for recursive, and 0.37\% faster for iterative).
Compiling the test programs with GCC 5.3, having an optimization level of O3 (large binary, fast code), we saw extremely low execution times for the native increment program as our function calls were essentially optimized away.
It is worth noting that the code generated by the LLVM recursive-fib outperformed the native optimized code.
Given two of our programs performed more quickly with MCJIT than with JitBuilder, it is interesting to examine the disassembly of the generated code.\footnote{We used GDB to print instructions starting at the function pointer address. The disassembly is using Intel style.}

Examining the recursive-fib disassembly for JitBuilder (code listing \ref{lst:jitbuilder_rfib_assembly}), we see it is using the stack for storage. We expect these additional loads and stores, used for passing arguments and return values, are the reason for the performance disparity.
The LLVM disassembly (code listing \ref{lst:llvm_rfib_assembly}) on the other hand, passes arguments using registers.
It's also interesting to see the condition for the jump comparison: \texttt{jg} 0x2 with LLVM and \texttt{jl} 0x2 in JitBuilder. 
We would expect the latter to be the better optimization considering most times \texttt{n} is greater than 2.
The code in the LLVM listing would perform relative jumps more often, while the code in the JitBuilder would flow through the instructions more often.

Looking at the estimated execution time minus JIT compilation for 1000 functions calls (see Table \ref{tab:1k_executions}), we can see that JitBuilder's generated code outperformed MCJIT both in the iterative-fib programs.\footnote{In our tests, the compile time plus the execution time of the JIT-ed function was less than the measurement for just the compilation. As noted earlier, we suspect this performance has to do with a high degree of cache locality. We subtracted the mean from Table \ref{tab:compile_time} from the mean from Table \ref{tab:1k_time_with_one_compile} without accounting for the variance. This may be incorrect. Unfortunately, time constraints limited our ability to properly benchmark 1000 executions of the JIT-ed code.}


\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|l|l|l|}
  \hline
  
  \multicolumn{1}{|l|}{\multirow{2}{*}{}} 
  & \multicolumn{3}{c|}{\textbf{LLVM MCJIT}}                                                                                    
  & \multicolumn{3}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                
  & \multicolumn{3}{c|}{\textbf{Native (C++)}}                                                                              
  \\ \cline{2-10}
  
  \multicolumn{1}{|c|}{\textbf{Program}}  
  & \multicolumn{1}{c|}{mean (ns)}  %llvm         
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}                     
  & \multicolumn{1}{c|}{mean (ns)}  %jb         
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}           
  & \multicolumn{1}{c|}{mean (ns)}  %native
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}                        
  \\ \hline
  
  increment                               
  & \num{1463310} %llvm
  & \num{1463032}                
  & \num{1660}                                        
  & \num{534192}  %jb                           
  & \num{534064}                 
  & \num{869}                                
  & \num{0.876}    %nat                          
  & \num{0.875}                   
  & \num{0.002}                                
  \\ \hline
  
  recursive-fib                           
  & \num{13674832}  %llvm                        
  & \num{13664199}               
  & \num{26548}                                        
  & \num{28707381}  %jb                         
  & \num{28699013}               
  & \num{29480}                               
  & \num{16016325}  %nat                        
  & \num{15996370}               
  & \num{60459}  
  \\ \hline
  
  iterative-fib                           
  & \num{2657528}   %llvm                         
  & \num{2668792}                
  & \num{83388}                                        
  & \num{4227967}   %jb                         
  & \num{4190232}                
  & \num{102744}                              
  & \num{0.876}     %nat                        
  & \num{0.875}                  
  & \num{0.003}                                
  \\ \hline
  \end{tabular}
  \caption{Results of JIT compiling each function once and executing the generated code 1000 times.}
  \label{tab:1k_time_with_one_compile}
\end{table*}

% Increment IR generation for JitBuilder
\begin{lstlisting}[float,floatplacement=H,
  caption={LLVM MCJIT recursive-fib disassembly (Optimization level 3)},
  label=lst:llvm_rfib_assembly]
(gdb) x/24i $1                                                              
  0x7ffff7fcd000 <fib>:        push   rbp                                  
  0x7ffff7fcd001 <fib+1>:      push   r14                                  
  0x7ffff7fcd003 <fib+3>:      push   rbx                                  
  0x7ffff7fcd004 <fib+4>:      cmp    edi,0x2                              
  0x7ffff7fcd007 <fib+7>:      jg     0x7ffff7fcd013 <fib+19>              
  0x7ffff7fcd009 <fib+9>:      mov    eax,0x1                              
  0x7ffff7fcd00e <fib+14>:     pop    rbx                                  
  0x7ffff7fcd00f <fib+15>:     pop    r14                                  
  0x7ffff7fcd011 <fib+17>:     pop    rbp                                  
  0x7ffff7fcd012 <fib+18>:     ret                                         
  0x7ffff7fcd013 <fib+19>:     mov    ebx,edi                              
  0x7ffff7fcd015 <fib+21>:     lea    edi,[rbx-0x1]                        
  0x7ffff7fcd018 <fib+24>:     movabs r14,0x7ffff7fcd000                   
  0x7ffff7fcd022 <fib+34>:     call   r14                                  
  0x7ffff7fcd025 <fib+37>:     mov    ebp,eax                              
  0x7ffff7fcd027 <fib+39>:     add    ebx,0xfffffffe                       
  0x7ffff7fcd02a <fib+42>:     mov    edi,ebx                              
  0x7ffff7fcd02c <fib+44>:     call   r14                                  
  0x7ffff7fcd02f <fib+47>:     add    eax,ebp                              
  0x7ffff7fcd031 <fib+49>:     pop    rbx                                  
  0x7ffff7fcd032 <fib+50>:     pop    r14                                  
  0x7ffff7fcd034 <fib+52>:     pop    rbp                                  
  0x7ffff7fcd035 <fib+53>:     ret    
\end{lstlisting}

\begin{lstlisting}[float,floatplacement=H,
caption={JitBuilder recursive-fib disassembly (Optimization level \textit{Warm})},
label=lst:jitbuilder_rfib_assembly]
(gdb) x/32i $1
  0x7ffff6a81034:	sub    rsp,0x18
  0x7ffff6a81038:	mov    QWORD PTR [rsp+0x10],rbx
  0x7ffff6a8103d:	cmp    edi,0x2
  0x7ffff6a81040:	jl     0x7ffff6a8106d
  0x7ffff6a81042:	mov    rbx,rdi
  0x7ffff6a81045:	lea    edi,[rbx-0x2]
  0x7ffff6a81048:	call   0x7ffff6a81034
  0x7ffff6a8104d:	mov    rdi,rbx
  0x7ffff6a81050:	mov    rbx,rax
  0x7ffff6a81053:	sub    edi,0x1
  0x7ffff6a81056:	call   0x7ffff6a81034
  0x7ffff6a8105b:	xchg   rbx,rax
  0x7ffff6a8105e:	mov    rcx,rbx
  0x7ffff6a81061:	add    eax,ecx
  0x7ffff6a81063:	mov    rbx,QWORD PTR [rsp+0x10]
  0x7ffff6a81068:	add    rsp,0x18
  0x7ffff6a8106c:	ret    
  0x7ffff6a8106d:	mov    rax,rdi
  0x7ffff6a81070:	mov    rbx,QWORD PTR [rsp+0x10]
  0x7ffff6a81075:	add    rsp,0x18
  0x7ffff6a81079:	ret   
\end{lstlisting}

\begin{table*}[t]
  \begin{tabular}{|r|l|l|} 
  \hline
  \multicolumn{1}{|c|}{\textbf{Program}}
  & \multicolumn{1}{c|}{\textbf{LLVM MCJIT}}                      
  & \multicolumn{1}{c|}{\textbf{Eclipse OMR JitBuilder}}
  \\ \hline

  increment                               
  & \multicolumn{1}{r|}{\num{85250}} %llvm      
  & \multicolumn{1}{r|}{\num{0}}     %jitbuilder               
  \\ \hline
  
  recursive-fib                           
  & \multicolumn{1}{r|}{\num{12126516}} %llvm       
  & \multicolumn{1}{r|}{\num{26852988}} %jitbuilder
  \\ \hline
  
  iterative-fib                           
  & \multicolumn{1}{r|}{\num{148026}} %llvm
  & \multicolumn{1}{r|}{\num{35754}} %jitbuilder
  \\ \hline
  
\end{tabular}
  \caption{Estimated time to execute JIT-ed function 1000 times.}
  \label{tab:1k_executions}
\end{table*}


\subsection{Binary File Size}
Looking at the size of the generated files (see Table \ref{tab:size_in_bytes}), the linked LLVM MCJIT programs are roughly six times larger in size than the JitBuilder programs.\footnote{The JIT frameworks were compiled without debug symbols.}
Part of the explanation for this may have to do with potentially over-linking the LLVM programs.
With over 167 possible linkable modules when using LLVM, we found what we think is the minimum number of modules required to use MCJIT.
These 8 modules are \textit{core, executionengine, interpreter, passes, mc, mcjit, support, nativecodegen}.

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|} 
  \hline
  \multicolumn{1}{|c|}{\textbf{Program}}
  & \multicolumn{1}{c|}{\textbf{LLVM MCJIT}}                      
  & \multicolumn{1}{c|}{\textbf{Eclipse OMR JitBuilder}}
  & \multicolumn{1}{c|}{\textbf{Native (C++)}}                    
  \\ \hline

  increment                               
  & \multicolumn{1}{r|}{\num{60640216}} %llvm      
  & \multicolumn{1}{r|}{\num{10148608}} %jitbuilder               
  & \multicolumn{1}{r|}{\num{16616}}    %native 
  \\ \hline
  
  recursive-fib                           
  & \multicolumn{1}{r|}{\num{60671176}} %llvm       
  & \multicolumn{1}{r|}{\num{10149272}} %jitbuilder
  & \multicolumn{1}{r|}{\num{16600}}   %native 
  \\ \hline
  
  iterative-fib                           
  & \multicolumn{1}{r|}{\num{60652728}} %llvm
  & \multicolumn{1}{r|}{\num{10149184}} %jitbuilder
  & \multicolumn{1}{r|}{\num{16600}}   %native 
  \\ \hline
  
\end{tabular}
  \caption{Total size in bytes of linked binary test programs.}
  \label{tab:size_in_bytes}
\end{table*}

\subsection{Resident State Set}
The resident state set (RSS) is amount of program memory during execution at any one time.
To measure the maximum RSS, we used the \texttt{time} utility (\texttt{/usr/bin/time -v}).
Looking at the results in Table \ref{tab:max_rss}, we see that LLVM consistently had the largest RSS.
The memory overhead required by LLVM is roughly 4.5 times larger than JitBuilder's requirement.
Looking at the number of times inactive pages were reclaimed during execution (minor page faults), we see that LLVM had roughly 4 times the number of inactive pages collected.

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|}
  \hline
  
  \multicolumn{1}{|l|}{\multirow{2}{*}{}} 
  & \multicolumn{1}{c|}{\textbf{LLVM MCJIT}}                                                                                    
  & \multicolumn{1}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                
  & \multicolumn{1}{c|}{\textbf{Native (C++)}}                                                                              
  \\ \cline{2-4}
  
  \multicolumn{1}{|c|}{\textbf{Program}}  
  & \multicolumn{1}{c|}{max RSS (kb)}  %llvm         
  & \multicolumn{1}{c|}{max RSS (kb)}  %jb         
  & \multicolumn{1}{c|}{max RSS (kb)}  %native         
  \\ \hline

  increment                               
  & \multicolumn{1}{r|}{\num{43544}} %llvm  
  & \multicolumn{1}{r|}{\num{9416}} %jitbuilder               
  & \multicolumn{1}{r|}{\num{1548}}    %native 
  \\ \hline
  
  recursive-fib                           
  & \multicolumn{1}{r|}{\num{45472}} %llvm       
  & \multicolumn{1}{r|}{\num{9768}} %jitbuilder
  & \multicolumn{1}{r|}{\num{1532}}   %native 
  \\ \hline
  
  iterative-fib                           
  & \multicolumn{1}{r|}{\num{44452}} %llvm
  & \multicolumn{1}{r|}{\num{10044}} %jitbuilder
  & \multicolumn{1}{r|}{\num{1684}}   %native 
  \\ \hline
  
\end{tabular}
  \caption{Maximum resident state set (RSS) in kilobytes during execution of a single compilation and execution of the generated function. A minor page fault occurs when the OS reclaims inactive pages during execution. Page size was 4096 bytes.}
  \label{tab:max_rss}
\end{table*}

\subsection{Developer Experience}
One additional aspect not typically included when considering overhead is the usability of the frameworks from a developer's perspective.
Under this banner we looked at two items: ease of use, and how configurable the frameworks were.

\subsubsection{Usability}
While ease of use is not likely to be the highest priority when considering which JIT framework to select, research has shown that improved API usability can positively impact developer productivity, while improving code quality and reducing errors \cite{apiUsability}.
Overall, we found that JitBuilder took less time to integrate, and provided a more intuitive API for generating IR.
When considering usability we took note of the following items:
\begin{itemize}
  \item Both of the frameworks provide public Github repositories \cite{llvmGithub,jitbuilderGithub}.
  \item The instructions for building the frameworks were readily available and simple to follow.
  \item Linking LLVM took considerable effort as it was unclear which of the 167 objects were required to use MCJIT. 
  After some trial and error, we discovered that LLVM provides a utility, \texttt{llvmconfig}, which simplifies this task by generating header and linking arguments based on a list of provided objects\footnote{Commands for building the programs can be found in \texttt{makefiles} in the accompanying source code under \texttt{src/<framework>/} \cite{projectGithub}.} 
  \item JitBuilder was relatively simple to integrate, requiring only a single header file and single module to link: \texttt{jitbuilder}, where as LLVM required us to include 20 header files.
  \item We found that writing the IR generators took less time with JitBuilder than with LLVM. 
  The most challenging was writing the iterative-fib generator for LLVM which included an induction value, a Phi node, several basic blocks for before, during and after the loop, condition values, as well as allocation and store pointers.\footnote{Source code for the LLVM iterative-fibonacci program can be found in the CreateFibFunction within \texttt{src/llvm/iterative-fib/fib.cpp}}.
  \item In every case the number of lines of code to generate the IR were fewer for JitBuilder. 
  This can be seen in the increment code listing for JitBuilder\ref{lst:jitbuilder_ir}, and for LLVM MCJIT\ref{lst:llvm_ir}.
  \item The in-memory objects generated by LLVM MCJIT can contain debug symbols (DWARF format) allowing debugging to take place in GDB 7.0 and higher \cite{llvmDebugJIT}.
\end{itemize}

\subsubsection{Configuration}
While the API of LLVM MCJIT may have an overabundance of controls, it does provide an high level of configuration compared to JitBuilder, including which optimization and analysis passes to run, control over the memory structure of the generated code, control over the object cache, and what level of optimization to generate the code at.
As mentioned, JitBuilder on the other hand is currently locked at the \textit{Warm} optimization level, limiting the number of optimizations performed on the IR.
