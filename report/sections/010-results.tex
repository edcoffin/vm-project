\section{Results}
\label{sec:results}
\subsection{Compilation Time}
The first question we looked at was how long each framework took to compile a function 25 times. This time includes running the program from start to finish and thus includes the setup and teardown time of the JIT.

In Table \ref{tab:compile_time} we see that for the increment task JitBuilder's compiled the function 61.5\% faster than MCJIT.
For the other two tasks, we see that MCJIT was able to compile the functions more quickly than JitBuilder (recursive-fib compiled 16.5\% faster, and iterative-fib compiled 40.1\% faster ).
Looking at the JitBuilder code to generate the function (see Listing \ref{lst:lst:jitbuilder_ir}), we see a much smaller function body compared to the function used to generate IR for LLVM (see Listing \ref{lst:llvm_increment}).
There is no clear reason why this disparity exists.
One idea is JitBuilder has a lower base overhead than LLVM, but the work required to generate code for more complex IR favours LLVM.
We will revisit this question when we look at the call-stack flame graphs.


\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|}
  \hline
  \multicolumn{1}{|l|}
  {\multirow{2}{*}{}} 
  & \multicolumn{3}{c|}{\textbf{LLVM MCJIT}}                                                                                                     & \multicolumn{3}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                              \\ \cline{2-7}
  
  \multicolumn{1}{|c|}{\textbf{Program}}
  & \multicolumn{1}{c|}{mean (ns)}  
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}     
  & \multicolumn{1}{c|}{mean (ns)}           
  & \multicolumn{1}{c|}{median} 
  & \multicolumn{1}{c|}{std. dev.}             
  \\ \hline
  
  increment                               
  & \num{1378060} %llvm                            
  & \num{1387338}                
  & \num{39774}               
  & \num{533581}  %jitbuilder                           
  & \num{531840}                
  & \num{4911}                                 
  \\ \hline
  
  recursive-fib                           
  & \num{1548316} %llvm                           
  & \num{1547491}                
  & \num{3925}                
  & \num{1854393} %jitbuilder                           
  & \num{1850322}               
  & \num{21754}
  \\ \hline
  
  iterative-fib                           
  & \num{2509502} %llvm                           
  & \num{2519808}                
  & \num{60429}              
  & \num{4192213} %jitbuilder                           
  & \num{4191730}               
  & \num{10419}                                
  \\ \hline
  
\end{tabular}
  \caption{Results of compiling each function 25 times with each JIT framework.}
  \label{tab:compile_time}
\end{table*}


% Increment IR generation for JitBuilder
\begin{lstlisting}[float,floatplacement=H,
  caption={Generating JitBuilder IR for the increment program.},
  label=lst:jitbuilder_increment]
  bool
  IncrementMethod::buildIL()
  {
    Return(
      Add(
          Load("value"),
          ConstInt32(1)));
    return true;
  }
  }\end{lstlisting}


% IR code for LLVM increment
\begin{lstlisting}[float,floatplacement=H,
  caption={Generating MCJIT IR for the increment program.},
  label=lst:llvm_increment]
  static Function *CreateIncrementFunction(
                    Module *M, 
                    LLVMContext &c) {
    FunctionType *f = FunctionType::get(Type::getInt32Ty(c), 
                        {Type::getInt32Ty(c)}, 
                        false);
    
    Function *incrementF = Function::Create(f, 
                        Function::ExternalLinkage, 
                        "increment", 
                        M);

    BasicBlock *BB = BasicBlock::Create(c, 
                        "EntryBlock", 
                        incrementF);
    
    Value *One = ConstantInt::get(Type::getInt32Ty(c), 1);
    
    Argument *ArgX = &*incrementF->arg_begin(); 
    ArgX->setName("AnArg");
  
    Value *Sum = BinaryOperator::CreateAdd(ArgX, 
                                  One,
                                  "addresult", 
                                  BB);
  
    ReturnInst::Create(c, Sum, BB);
    return incrementF;
  }
}\end{lstlisting}

\subsection{Execution Time}
Once compilation has completed we turn to measuring how much CPU time is spent actually executing the function.
To measure this we compiled the function once and then executed the compiled function 1000 times.
For each program, the process was repeated 20 times (see Table \ref{tab:1k_time}).
Aside from the increment program, which favoured JitBuilder, both the recursive and iterative fib functions executed more quickly with LLVM generated code (0.53\% faster for recursive, and 0.37\% faster for iterative).
Compiling the test programs GCC 5.3 with an optimization level of O3 resulted in extremely low execution times for the native increment program as our function calls were optimized away.
It is worth noting that the code generated by the LLVM recursive-fib outperformed the native optimized code.

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|l|l|l|}
  \hline
  
  \multicolumn{1}{|l|}{\multirow{2}{*}{}} 
  & \multicolumn{3}{c|}{\textbf{LLVM MCJIT}}                                                                                    
  & \multicolumn{3}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                
  & \multicolumn{3}{c|}{\textbf{Native (C++)}}                                                                              
  \\ \cline{2-10}
  
  \multicolumn{1}{|c|}{\textbf{Program}}  
  & \multicolumn{1}{c|}{mean (ns)}  %llvm         
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}                     
  & \multicolumn{1}{c|}{mean (ns)}  %jb         
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}           
  & \multicolumn{1}{c|}{mean (ns)}  %native
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}                        
  \\ \hline
  
  increment                               
  & \num{1463310} %llvm
  & \num{1463032}                
  & \num{1660}                                        
  & \num{524723}  %jb                           
  & \num{524763}                 
  & \num{718}                                
  & \num{0.876}    %nat                          
  & \num{0.875}                   
  & \num{0.002}                                
  \\ \hline
  
  recursive-fib                           
  & \num{13674832}  %llvm                        
  & \num{13664199}               
  & \num{26548}                                        
  & \num{28707381}  %jb                         
  & \num{28699013}               
  & \num{29480}                               
  & \num{16016325}  %nat                        
  & \num{15996370}               
  & \num{60459}  
  \\ \hline
  
  iterative-fib                           
  & \num{2657528}   %llvm                         
  & \num{2668792}                
  & \num{83388}                                        
  & \num{4227967}   %jb                         
  & \num{4190232}                
  & \num{102744}                              
  & \num{0.876}     %nat                        
  & \num{0.875}                  
  & \num{0.003}                                
  \\ \hline
  \end{tabular}
  \caption{Results of compiling each function and executing generated function 1000 times.}
  \label{tab:1k_time}
\end{table*}

\subsection{Binary File Size}
Looking at the size of the generated files (see Table \ref{tab:size_in_bytes}), the linked LLVM MCJIT programs are roughly six times larger in size than the JitBuilder programs.
Note that the JIT frameworks were compiled without debug symbols.
Part of the explanation for this is may have to do with over-linking the LLVM programs.
While there are over 167 possible linkable modules when using LLVM, I found the minimal set required to use MCJIT was just 8 : \textit{core, executionengine, interpreter, passes, mc, mcjit, support, nativecodegen}.

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|} 
  \hline
  \multicolumn{1}{|c|}{\textbf{Program}}
  & \multicolumn{1}{c|}{\textbf{LLVM MCJIT}}                      & \multicolumn{1}{c|}{\textbf{Eclipse OMR JitBuilder}}
  & \multicolumn{1}{c|}{\textbf{Native (C++)}}                    \\ \hline

  increment                               
  & \multicolumn{1}{r|}{\num{60640216}} %llvm      
  & \multicolumn{1}{r|}{\num{10148608}} %jitbuilder               
  & \multicolumn{1}{r|}{\num{16616}}    %native 
  \\ \hline
  
  recursive-fib                           
  & \multicolumn{1}{r|}{\num{60671176}} %llvm       
  & \multicolumn{1}{r|}{\num{10149272}} %jitbuilder
  & \multicolumn{1}{r|}{\num{16600}}   %native 
  \\ \hline
  
  iterative-fib                           
  & \multicolumn{1}{r|}{\num{60652728}} %llvm
  & \multicolumn{1}{r|}{\num{10149184}} %jitbuilder
  & \multicolumn{1}{r|}{\num{16600}}   %native 
  \\ \hline
  
\end{tabular}
  \caption{Total size in bytes of linked binary test programs.}
  \label{tab:size_in_bytes}
\end{table*}

\subsection{Resident State Set}
The resident state (RSS) set is amount of data loaded into RAM during execution at any one time.
To measure the maximum RSS, we used the \texttt{time} utility (\texttt{/usr/bin/time -v}) to collect this.
Looking at the results in Table \ref{tab:max_rss}, we see that LLVM consistently had the largest RSS.
The memory overhead required by LLVM is roughly 4.5 times larger than JitBuilder's requirement.
Looking at the number of times inactive pages were reclaimed during execution (minor page faults), we see that LLVM had roughly 4 times the number of inactive pages collected.

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|}
  \hline
  
  \multicolumn{1}{|l|}{\multirow{2}{*}{}} 
  & \multicolumn{2}{c|}{\textbf{LLVM MCJIT}}                                                                                    
  & \multicolumn{2}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                
  & \multicolumn{2}{c|}{\textbf{Native (C++)}}                                                                              
  \\ \cline{2-7}
  
  \multicolumn{1}{|c|}{\textbf{Program}}  
  & \multicolumn{1}{c|}{max RSS (kb)}  %llvm         
  & \multicolumn{1}{c|}{minor page faults}  
  & \multicolumn{1}{c|}{max RSS (kb)}  %jb         
  & \multicolumn{1}{c|}{minor page faults}  
  & \multicolumn{1}{c|}{max RSS (kb)}  %native         
  & \multicolumn{1}{c|}{minor page faults}  
  \\ \hline

  increment                               
  & \multicolumn{1}{r|}{\num{43544}} %llvm  
  & \multicolumn{1}{r|}{\num{1478}} 
  & \multicolumn{1}{r|}{\num{9416}} %jitbuilder               
  & \multicolumn{1}{r|}{\num{344}}
  & \multicolumn{1}{r|}{\num{1548}}    %native 
  & \multicolumn{1}{r|}{\num{65}}
  \\ \hline
  
  recursive-fib                           
  & \multicolumn{1}{r|}{\num{45472}} %llvm       
  & \multicolumn{1}{r|}{\num{1545}} 
  & \multicolumn{1}{r|}{\num{9768}} %jitbuilder
  & \multicolumn{1}{r|}{\num{384}} 
  & \multicolumn{1}{r|}{\num{1532}}   %native 
  & \multicolumn{1}{r|}{\num{63}} 
  \\ \hline
  
  iterative-fib                           
  & \multicolumn{1}{r|}{\num{44452}} %llvm
  & \multicolumn{1}{r|}{\num{1520}}
  & \multicolumn{1}{r|}{\num{10044}} %jitbuilder
  & \multicolumn{1}{r|}{\num{423}}
  & \multicolumn{1}{r|}{\num{1684}}   %native 
  & \multicolumn{1}{r|}{\num{66}}  
  \\ \hline
  
\end{tabular}
  \caption{Maximum resident state set (RSS) in kilobytes during execution of a single compilation and execution of the generated function. Note that Native had no run-time compilation phase. A minor page fault occurs when the OS reclaims inactive pages during execution. Page size was 4096 bytes.}
  \label{tab:max_rss}
\end{table*}

\subsection{Developer Experience}
One additional aspect to overhead worth considering is the usability of the frameworks from a developer's perspective.
Under this banner, we looked at two items: ease of use, and how configurable the frameworks were.

\subsubsection{Usability}
While ease of use is not likely to be the highest priority when considering which JIT framework to select, research has shown that improved API usability can positively impact developer productivity \cite{apiUsability}, while improving code quality and reducing errors.
Overall we found that JitBuilder took less time to integrate, and provided a more intuitive API for generating IR.
When considering usability we took note of the following items:
\begin{itemize}
  \item Both of the frameworks provide public Github repositories \cite{llvmGithub,jitbuilderGithub}.
  \item The instructions for building the frameworks were readily available and simple to follow.
  \item Linking LLVM took considerable effort as it was unclear which of the 167 objects were required to use MCJIT. After some trial and error, we discovered LLVM provides a utility, \texttt{llvmconfig}, which simplifies this task by generating header and linking arguments for G++ based on a list of objects\footnote{Example commands for building the programs can be found \texttt{makefiles} in the accompanying source code \cite{projectGithub} under \texttt{src/<framework>/}.} 
  \item JitBuilder on the other hand required was simple to integrate, requiring only a single header file and single module to link: \texttt{jitbuilder}. On the other hand, LLVM required us to include 20 header files in our programs.
  \item We found that writing the IR generators in our test programs took less time with JitBuilder than with LLVM. 
  The most challenging task was writing iterative-fib for LLVM, as this required us to grasp the underlying IR requirements which included: an induction value, a Phi node, several basic blocks for before, during and after the loop, condition values, as well as allocation and store pointers.\footnote{Source code for the LLVM iterative-fibonacci program can be found in the CreateFibFunction within \texttt{src/llvm/iterative-fib/fib.cpp}}.
  \item The in memory objects generated by LLVM MCJIT can contain debug symbols (DWARF format) allowing debugging to take place in GDB 7.0 and higher \cite{llvmDebugJIT}.
\end{itemize}

\subsubsection{Configuration}
While the API of LLVM MCJIT may have an overabundance of controls, it does provide an high level of configuration compared to JitBuilder, including which optimization and analysis passes to run, control over the memory structure of the generated code, control over the object cache, and what level of optimization to generate the code at.
As mentioned, JitBuilder on the other hand is currently locked at the \textit{Warm} optimization level, limiting the number of optimizations performed on the IR.

\subsection{Considerations}
Considering the JIT compiler behind JitBuilder was designed specifically for dynamic runtime compilation, it makes sense that it has a lighter footprint than MCJIT, which shares it's codebase with the static compiler for LLVM
Unlike LLVM's IR, which is meant for life-long usage, the design of OMR's IR does not have ahead of time, or offline goals in mind, thus
possibly simplifying the work required whenever IR interactions are made in JitBuilder.
