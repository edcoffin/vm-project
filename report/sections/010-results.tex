\section{Results}
\label{sec:results}
\subsection{Compilation Time}
The first question we looked at was how long each framework took to compile a function 25 times. This time includes running the program from start to finish and thus includes the setup and teardown time of the JIT.

In Table \ref{tab:compile_time} we see that for the increment task JitBuilder's compiled the function 61.5\% faster than MCJIT.
For the other two tasks, we see that MCJIT was able to compile the functions more quickly than JitBuilder (recursive-fib compiled 16.5\% faster, and iterative-fib compiled 40.1\% faster ).
Looking at the JitBuilder code to generate the function (see Listing \ref{lst:lst:jitbuilder_ir}), we see a much smaller function body compared to the function used to generate IR for LLVM (see Listing \ref{lst:llvm_increment}).
There is no clear reason why this disparity exists.
One idea is JitBuilder has a lower base overhead than LLVM, but the work required to generate code for more complex IR favours LLVM.
We will revisit this question when we look at the call-stack flame graphs.

\begin{lstlisting}[float,floatplacement=H,
caption={Generating JitBuilder IR for the increment program.},
label=lst:jitbuilder_increment]
bool
IncrementMethod::buildIL()
{
  Return(
    Add(
        Load("value"),
        ConstInt32(1)));
  return true;
}
}\end{lstlisting}


\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|}
  \hline
  \multicolumn{1}{|l|}{\multirow{2}{*}{}} & \multicolumn{3}{c|}{\textbf{LLVM MCJIT}}                                                                                                       & \multicolumn{3}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                              \\ \cline{2-7}
  \multicolumn{1}{|c|}{\textbf{Program}}  & \multicolumn{1}{c|}{mean (ns)}  & \multicolumn{1}{c|}{median}  & \multicolumn{1}{c|}{std. dev.}     & \multicolumn{1}{c|}{mean (ns)}           & \multicolumn{1}{c|}{median} & \multicolumn{1}{c|}{std. dev.}             \\ \hline
  increment                               & \num{1378060}                            & \num{1387338}                & \num{39774}               & \num{533581}                             & \num{531840}                & \num{4911}                                 \\ \hline
  recursive-fib                           & \num{1548316}                            & \num{1547491}                & \num{3925}                & \num{1854393}                            & \num{1850322}               & \num{21754}                                \\ \hline
  iterative-fib                           & \num{2509502}                            & \num{2519808}                & \num{60429}               & \num{4192213}                            & \num{4191730}               & \num{10419}                                \\ \hline
  \end{tabular}
  \caption{Results of compiling each function 25 times with each JIT framework.}
  \label{tab:compile_time}
\end{table*}

\begin{lstlisting}[float,floatplacement=H,
  caption={Generating MCJIT IR for the increment program.},
  label=lst:llvm_increment]
  static Function *CreateIncrementFunction(
                    Module *M, 
                    LLVMContext &c) {
    FunctionType *f = FunctionType::get(Type::getInt32Ty(c), 
                        {Type::getInt32Ty(c)}, 
                        false);
    
    Function *incrementF = Function::Create(f, 
                        Function::ExternalLinkage, 
                        "increment", 
                        M);

    BasicBlock *BB = BasicBlock::Create(c, 
                        "EntryBlock", 
                        incrementF);
    
    Value *One = ConstantInt::get(Type::getInt32Ty(c), 1);
    
    Argument *ArgX = &*incrementF->arg_begin(); 
    ArgX->setName("AnArg");
  
    Value *Sum = BinaryOperator::CreateAdd(ArgX, 
                                  One,
                                  "addresult", 
                                  BB);
  
    ReturnInst::Create(c, Sum, BB);
    return incrementF;
  }
}\end{lstlisting}

\subsection{Execution Time}
Once compilation has completed we turn to measuring how much CPU time is spent actually executing the function.
To measure this we compiled the function once and then executed the compiled function 1000 times.
For each program, the process was repeated 20 times (see Table \ref{tab:1k_time}).
Compiling the test programs GCC 5.3 with an optimization level of O3 resulted in extremely low execution times for the native increment program as our function calls were optimized away.

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|l|l|l|}
  \hline
  
  \multicolumn{1}{|l|}{\multirow{2}{*}{}} 
  & \multicolumn{3}{c|}{\textbf{LLVM MCJIT}}                                                                                    
  & \multicolumn{3}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                
  & \multicolumn{3}{c|}{\textbf{Native (C++)}}                                                                              
  \\ \cline{2-10}
  
  \multicolumn{1}{|c|}{\textbf{Program}}  
  & \multicolumn{1}{c|}{mean (ns)}  %llvm         
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}                     
  & \multicolumn{1}{c|}{mean (ns)}  %jb         
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}           
  & \multicolumn{1}{c|}{mean (ns)}  %native
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}                        
  \\ \hline
  
  increment                               
  & \num{1463310} %llvm
  & \num{1463032}                
  & \num{1660}                                        
  & \num{524723}  %jb                           
  & \num{524763}                 
  & \num{718}                                
  & \num{0.876}    %nat                          
  & \num{0.875}                   
  & \num{0.002}                                
  \\ \hline
  
  recursive-fib                           
  & \num{13674832}  %llvm                        
  & \num{13664199}               
  & \num{26548}                                        
  & \num{28707381}  %jb                         
  & \num{28699013}               
  & \num{29480}                               
  & \num{31404538}  %nat                        
  & \num{31319334}               
  & \num{142705}  
  \\ \hline
  
  iterative-fib                           
  & \num{2657528}   %llvm                         
  & \num{2668792}                
  & \num{83388}                                        
  & \num{4227967}   %jb                         
  & \num{4190232}                
  & \num{102744}                              
  & \num{37379}     %nat                        
  & \num{37516}                  
  & \num{583}                                
  \\ \hline
  \end{tabular}
  \caption{Results of compiling each function and executing generated function 1000 times.}
  \label{tab:1k_time}
\end{table*}

\subsection{Max Resident State Set}

\subsection{Binary File Size}

\subsection{Considerations}
Considering the JIT compiler behind JitBuilder was originally designed for dynamic runtime compilation, it makes sense that it has a lighter footprint than LLVM -- both in terms of RSS and linked file size.
Unlike LLVM's IR, which is meant for life-long usage, the design of OMR's IR does not have the goals in mind.
Perhaps this may somewhat limit the overhead of JitBuilder when analyzing and transforming the IR.
