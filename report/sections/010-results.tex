\section{Results}
\label{sec:results}
\subsection{Compilation Time}
The first question we looked at was how long each framework took to compile a function 25 times. This time includes running the program from start to finish and thus includes the setup and teardown time of the JIT.

In Table \ref{tab:compile_time} we see that for the increment task JitBuilder's compiled the function 61.5\% faster than MCJIT.
Looking into this further, the initial run to compile the function would take roughly 900,000 nanoseconds.
Repeated executions made by our benchmarking framework Google Benchmark\cite{googleBench} would take closer to 500,000 nanoseconds as the instructions for this relatively small example would be cached.
For the other two tasks, we see that MCJIT was able to compile the functions more quickly than JitBuilder (recursive-fib compiled 16.5\% faster, and iterative-fib compiled 40.1\% faster ).
Looking at the JitBuilder code to generate the function (see Listing \ref{lst:lst:jitbuilder_ir}), we see a much smaller function body compared to the function used to generate IR for LLVM (see Listing \ref{lst:llvm_increment}).
%We will revisit this question when we look at the call-stack flame graphs.


\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|}
  \hline
  \multicolumn{1}{|l|}
  {\multirow{2}{*}{}} 
  & \multicolumn{3}{c|}{\textbf{LLVM MCJIT}}                                                                                                     & \multicolumn{3}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                              \\ \cline{2-7}
  
  \multicolumn{1}{|c|}{\textbf{Program}}
  & \multicolumn{1}{c|}{mean (ns)}  
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}     
  & \multicolumn{1}{c|}{mean (ns)}           
  & \multicolumn{1}{c|}{median} 
  & \multicolumn{1}{c|}{std. dev.}             
  \\ \hline
  
  increment                               
  & \num{1378060} %llvm                            
  & \num{1387338}                
  & \num{39774}               
  & \num{536741}  %jitbuilder                           
  & \num{537103}                
  & \num{2620}                                 
  \\ \hline
  
  recursive-fib                           
  & \num{1548316} %llvm                           
  & \num{1547491}                
  & \num{3925}                
  & \num{1854393} %jitbuilder                           
  & \num{1850322}               
  & \num{21754}
  \\ \hline
  
  iterative-fib                           
  & \num{2509502} %llvm                           
  & \num{2519808}                
  & \num{60429}              
  & \num{4192213} %jitbuilder                           
  & \num{4191730}               
  & \num{10419}                                
  \\ \hline
  
\end{tabular}
  \caption{Results of compiling each function 25 times with each JIT framework.}
  \label{tab:compile_time}
\end{table*}


% Increment IR generation for JitBuilder
\begin{lstlisting}[float,floatplacement=H,
  caption={Generating JitBuilder IR for the increment program.},
  label=lst:jitbuilder_increment]
  bool
  IncrementMethod::buildIL()
  {
    Return(
      Add(
          Load("value"),
          ConstInt32(1)));
    return true;
  }
  }\end{lstlisting}


% IR code for LLVM increment
\begin{lstlisting}[float,floatplacement=H,
  caption={Generating MCJIT IR for the increment program.},
  label=lst:llvm_increment]
  static Function *CreateIncrementFunction(
                    Module *M, 
                    LLVMContext &c) {
    FunctionType *f = FunctionType::get(Type::getInt32Ty(c), 
                        {Type::getInt32Ty(c)}, 
                        false);
    
    Function *incrementF = Function::Create(f, 
                        Function::ExternalLinkage, 
                        "increment", 
                        M);

    BasicBlock *BB = BasicBlock::Create(c, 
                        "EntryBlock", 
                        incrementF);
    
    Value *One = ConstantInt::get(Type::getInt32Ty(c), 1);
    
    Argument *ArgX = &*incrementF->arg_begin(); 
    ArgX->setName("AnArg");
  
    Value *Sum = BinaryOperator::CreateAdd(ArgX, 
                                  One,
                                  "addresult", 
                                  BB);
  
    ReturnInst::Create(c, Sum, BB);
    return incrementF;
  }
}\end{lstlisting}

\subsection{Execution Time}
Once compilation has completed we turn to measuring how much CPU time is spent actually executing the function.
To measure this we compiled the function once and then executed the compiled function 1000 times.
For each program, the process was repeated 20 times (see Table \ref{tab:1k_time_with_one_compile}).
Aside from the increment program, which favoured JitBuilder, both the recursive and iterative fib functions executed more quickly with LLVM generated code (0.53\% faster for recursive, and 0.37\% faster for iterative).
Compiling the test programs GCC 5.3 with an optimization level of O3 resulted in extremely low execution times for the native increment program as our function calls were optimized away.
It is worth noting that the code generated by the LLVM recursive-fib outperformed the native optimized code.
Given two of our programs performed more quickly with MCJIT than with JitBuilder, it is interesting to examine the disassembly of the generated code.\footnote{We used GDB to print instructions starting at the function pointer address. The disassembly is using Intel style.}
Examining the recursive-fib disassembly for JitBuilder\ref{lst:jitbuilder_rfib_assembly}, we see it is using a stack for storages. These additional loads and stores at indirect offsets (from rsp) for passing arguments and return values are likely the culprit in the performance disparity.
The LLVM disassembly on the other hand does away with loads and stores to the stack for argument passing (though we still see register preserving via push and pop).
It's interesting to see the condition for the jump comparison: \texttt{jg} 0x2 with LLVM and \texttt{jl} 0x2 in JitBuilder. I would expect the latter to be a better optimization considering most times \texttt{n} is greater than 2.
The code in the LLVM listing would be performing a relative jump more often, while the code in the JitBuilder would flow through the instruction more often.

Looking at the estimated execution time without compilation for 1000 generated functions (see Table \ref{tab:1k_executions}), we can see that JitBuilder's generated code may outperform LLVM \footnote{We subtracted the mean from Table\ref{tab:compile_time} from the mean from Table\ref{tab:1k_time_with_one_compile} without accounting for the variance. This may be incorrect. Unfortunately, time constraints limited our ability to properly benchmark 1000 executions of the JIT-ed code.}

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|l|l|l|}
  \hline
  
  \multicolumn{1}{|l|}{\multirow{2}{*}{}} 
  & \multicolumn{3}{c|}{\textbf{LLVM MCJIT}}                                                                                    
  & \multicolumn{3}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                
  & \multicolumn{3}{c|}{\textbf{Native (C++)}}                                                                              
  \\ \cline{2-10}
  
  \multicolumn{1}{|c|}{\textbf{Program}}  
  & \multicolumn{1}{c|}{mean (ns)}  %llvm         
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}                     
  & \multicolumn{1}{c|}{mean (ns)}  %jb         
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}           
  & \multicolumn{1}{c|}{mean (ns)}  %native
  & \multicolumn{1}{c|}{median}  
  & \multicolumn{1}{c|}{std. dev.}                        
  \\ \hline
  
  increment                               
  & \num{1463310} %llvm
  & \num{1463032}                
  & \num{1660}                                        
  & \num{534192}  %jb                           
  & \num{534064}                 
  & \num{869}                                
  & \num{0.876}    %nat                          
  & \num{0.875}                   
  & \num{0.002}                                
  \\ \hline
  
  recursive-fib                           
  & \num{13674832}  %llvm                        
  & \num{13664199}               
  & \num{26548}                                        
  & \num{28707381}  %jb                         
  & \num{28699013}               
  & \num{29480}                               
  & \num{16016325}  %nat                        
  & \num{15996370}               
  & \num{60459}  
  \\ \hline
  
  iterative-fib                           
  & \num{2657528}   %llvm                         
  & \num{2668792}                
  & \num{83388}                                        
  & \num{4227967}   %jb                         
  & \num{4190232}                
  & \num{102744}                              
  & \num{0.876}     %nat                        
  & \num{0.875}                  
  & \num{0.003}                                
  \\ \hline
  \end{tabular}
  \caption{Results of JIT compiling each function once and executing the generated code 1000 times.}
  \label{tab:1k_time_with_one_compile}
\end{table*}

% Increment IR generation for JitBuilder
\begin{lstlisting}[float,floatplacement=H,
  caption={LLVM MCJIT recursive-fib disassembly (Optimization level 3)},
  label=lst:llvm_rfib_assembly]
(gdb) x/24i $1                                                              
  0x7ffff7fcd000 <fib>:        push   rbp                                  
  0x7ffff7fcd001 <fib+1>:      push   r14                                  
  0x7ffff7fcd003 <fib+3>:      push   rbx                                  
  0x7ffff7fcd004 <fib+4>:      cmp    edi,0x2                              
  0x7ffff7fcd007 <fib+7>:      jg     0x7ffff7fcd013 <fib+19>              
  0x7ffff7fcd009 <fib+9>:      mov    eax,0x1                              
  0x7ffff7fcd00e <fib+14>:     pop    rbx                                  
  0x7ffff7fcd00f <fib+15>:     pop    r14                                  
  0x7ffff7fcd011 <fib+17>:     pop    rbp                                  
  0x7ffff7fcd012 <fib+18>:     ret                                         
  0x7ffff7fcd013 <fib+19>:     mov    ebx,edi                              
  0x7ffff7fcd015 <fib+21>:     lea    edi,[rbx-0x1]                        
  0x7ffff7fcd018 <fib+24>:     movabs r14,0x7ffff7fcd000                   
  0x7ffff7fcd022 <fib+34>:     call   r14                                  
  0x7ffff7fcd025 <fib+37>:     mov    ebp,eax                              
  0x7ffff7fcd027 <fib+39>:     add    ebx,0xfffffffe                       
  0x7ffff7fcd02a <fib+42>:     mov    edi,ebx                              
  0x7ffff7fcd02c <fib+44>:     call   r14                                  
  0x7ffff7fcd02f <fib+47>:     add    eax,ebp                              
  0x7ffff7fcd031 <fib+49>:     pop    rbx                                  
  0x7ffff7fcd032 <fib+50>:     pop    r14                                  
  0x7ffff7fcd034 <fib+52>:     pop    rbp                                  
  0x7ffff7fcd035 <fib+53>:     ret    
\end{lstlisting}

\begin{lstlisting}[float,floatplacement=H,
caption={JitBuilder recursive-fib disassembly (Optimization level \textit{Warm})},
label=lst:jitbuilder_rfib_assembly]
(gdb) x/32i $1
  0x7ffff6a81034:	sub    rsp,0x18
  0x7ffff6a81038:	mov    QWORD PTR [rsp+0x10],rbx
  0x7ffff6a8103d:	cmp    edi,0x2
  0x7ffff6a81040:	jl     0x7ffff6a8106d
  0x7ffff6a81042:	mov    rbx,rdi
  0x7ffff6a81045:	lea    edi,[rbx-0x2]
  0x7ffff6a81048:	call   0x7ffff6a81034
  0x7ffff6a8104d:	mov    rdi,rbx
  0x7ffff6a81050:	mov    rbx,rax
  0x7ffff6a81053:	sub    edi,0x1
  0x7ffff6a81056:	call   0x7ffff6a81034
  0x7ffff6a8105b:	xchg   rbx,rax
  0x7ffff6a8105e:	mov    rcx,rbx
  0x7ffff6a81061:	add    eax,ecx
  0x7ffff6a81063:	mov    rbx,QWORD PTR [rsp+0x10]
  0x7ffff6a81068:	add    rsp,0x18
  0x7ffff6a8106c:	ret    
  0x7ffff6a8106d:	mov    rax,rdi
  0x7ffff6a81070:	mov    rbx,QWORD PTR [rsp+0x10]
  0x7ffff6a81075:	add    rsp,0x18
  0x7ffff6a81079:	ret   
\end{lstlisting}

\begin{table*}[t]
  \begin{tabular}{|r|l|l|} 
  \hline
  \multicolumn{1}{|c|}{\textbf{Program}}
  & \multicolumn{1}{c|}{\textbf{LLVM MCJIT}}                      
  & \multicolumn{1}{c|}{\textbf{Eclipse OMR JitBuilder}}
  \\ \hline

  increment                               
  & \multicolumn{1}{r|}{\num{85250}} %llvm      
  & \multicolumn{1}{r|}{\num{0}}     %jitbuilder               
  \\ \hline
  
  recursive-fib                           
  & \multicolumn{1}{r|}{\num{12126516}} %llvm       
  & \multicolumn{1}{r|}{\num{26852988}} %jitbuilder
  \\ \hline
  
  iterative-fib                           
  & \multicolumn{1}{r|}{\num{148026}} %llvm
  & \multicolumn{1}{r|}{\num{35754}} %jitbuilder
  \\ \hline
  
\end{tabular}
  \caption{Estimated time to execute JIT function 1000 times (mean from Table \ref{tab:1k_time_with_one_compile} - mean from Table \ref{tab:compile_time}).}
  \label{tab:1k_executions}
\end{table*}


\subsection{Binary File Size}
Looking at the size of the generated files (see Table \ref{tab:size_in_bytes}), the linked LLVM MCJIT programs are roughly six times larger in size than the JitBuilder programs.
Note that the JIT frameworks were compiled without debug symbols.
Part of the explanation for this is may have to do with over-linking the LLVM programs.
While there are over 167 possible linkable modules when using LLVM, I found the minimal set required to use MCJIT was just 8 : \textit{core, executionengine, interpreter, passes, mc, mcjit, support, nativecodegen}.

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|} 
  \hline
  \multicolumn{1}{|c|}{\textbf{Program}}
  & \multicolumn{1}{c|}{\textbf{LLVM MCJIT}}                      
  & \multicolumn{1}{c|}{\textbf{Eclipse OMR JitBuilder}}
  & \multicolumn{1}{c|}{\textbf{Native (C++)}}                    
  \\ \hline

  increment                               
  & \multicolumn{1}{r|}{\num{60640216}} %llvm      
  & \multicolumn{1}{r|}{\num{10148608}} %jitbuilder               
  & \multicolumn{1}{r|}{\num{16616}}    %native 
  \\ \hline
  
  recursive-fib                           
  & \multicolumn{1}{r|}{\num{60671176}} %llvm       
  & \multicolumn{1}{r|}{\num{10149272}} %jitbuilder
  & \multicolumn{1}{r|}{\num{16600}}   %native 
  \\ \hline
  
  iterative-fib                           
  & \multicolumn{1}{r|}{\num{60652728}} %llvm
  & \multicolumn{1}{r|}{\num{10149184}} %jitbuilder
  & \multicolumn{1}{r|}{\num{16600}}   %native 
  \\ \hline
  
\end{tabular}
  \caption{Total size in bytes of linked binary test programs.}
  \label{tab:size_in_bytes}
\end{table*}

\subsection{Resident State Set}
The resident state (RSS) set is amount of data loaded into RAM during execution at any one time.
To measure the maximum RSS, we used the \texttt{time} utility (\texttt{/usr/bin/time -v}) to collect this.
Looking at the results in Table \ref{tab:max_rss}, we see that LLVM consistently had the largest RSS.
The memory overhead required by LLVM is roughly 4.5 times larger than JitBuilder's requirement.
Looking at the number of times inactive pages were reclaimed during execution (minor page faults), we see that LLVM had roughly 4 times the number of inactive pages collected.

\begin{table*}[t]
  \begin{tabular}{|r|l|l|l|l|l|l|}
  \hline
  
  \multicolumn{1}{|l|}{\multirow{2}{*}{}} 
  & \multicolumn{2}{c|}{\textbf{LLVM MCJIT}}                                                                                    
  & \multicolumn{2}{c|}{\textbf{Eclipse OMR JitBuilder}}                                                                
  & \multicolumn{2}{c|}{\textbf{Native (C++)}}                                                                              
  \\ \cline{2-7}
  
  \multicolumn{1}{|c|}{\textbf{Program}}  
  & \multicolumn{1}{c|}{max RSS (kb)}  %llvm         
  & \multicolumn{1}{c|}{minor page faults}  
  & \multicolumn{1}{c|}{max RSS (kb)}  %jb         
  & \multicolumn{1}{c|}{minor page faults}  
  & \multicolumn{1}{c|}{max RSS (kb)}  %native         
  & \multicolumn{1}{c|}{minor page faults}  
  \\ \hline

  increment                               
  & \multicolumn{1}{r|}{\num{43544}} %llvm  
  & \multicolumn{1}{r|}{\num{1478}} 
  & \multicolumn{1}{r|}{\num{9416}} %jitbuilder               
  & \multicolumn{1}{r|}{\num{344}}
  & \multicolumn{1}{r|}{\num{1548}}    %native 
  & \multicolumn{1}{r|}{\num{65}}
  \\ \hline
  
  recursive-fib                           
  & \multicolumn{1}{r|}{\num{45472}} %llvm       
  & \multicolumn{1}{r|}{\num{1545}} 
  & \multicolumn{1}{r|}{\num{9768}} %jitbuilder
  & \multicolumn{1}{r|}{\num{384}} 
  & \multicolumn{1}{r|}{\num{1532}}   %native 
  & \multicolumn{1}{r|}{\num{63}} 
  \\ \hline
  
  iterative-fib                           
  & \multicolumn{1}{r|}{\num{44452}} %llvm
  & \multicolumn{1}{r|}{\num{1520}}
  & \multicolumn{1}{r|}{\num{10044}} %jitbuilder
  & \multicolumn{1}{r|}{\num{423}}
  & \multicolumn{1}{r|}{\num{1684}}   %native 
  & \multicolumn{1}{r|}{\num{66}}  
  \\ \hline
  
\end{tabular}
  \caption{Maximum resident state set (RSS) in kilobytes during execution of a single compilation and execution of the generated function. Note that Native had no run-time compilation phase. A minor page fault occurs when the OS reclaims inactive pages during execution. Page size was 4096 bytes.}
  \label{tab:max_rss}
\end{table*}

\subsection{Developer Experience}
One additional aspect to overhead worth considering is the usability of the frameworks from a developer's perspective.
Under this banner, we looked at two items: ease of use, and how configurable the frameworks were.

\subsubsection{Usability}
While ease of use is not likely to be the highest priority when considering which JIT framework to select, research has shown that improved API usability can positively impact developer productivity \cite{apiUsability}, while improving code quality and reducing errors.
Overall we found that JitBuilder took less time to integrate, and provided a more intuitive API for generating IR.
When considering usability we took note of the following items:
\begin{itemize}
  \item Both of the frameworks provide public Github repositories \cite{llvmGithub,jitbuilderGithub}.
  \item The instructions for building the frameworks were readily available and simple to follow.
  \item Linking LLVM took considerable effort as it was unclear which of the 167 objects were required to use MCJIT. After some trial and error, we discovered LLVM provides a utility, \texttt{llvmconfig}, which simplifies this task by generating header and linking arguments for G++ based on a list of objects\footnote{Example commands for building the programs can be found \texttt{makefiles} in the accompanying source code \cite{projectGithub} under \texttt{src/<framework>/}.} 
  \item JitBuilder on the other hand required was simple to integrate, requiring only a single header file and single module to link: \texttt{jitbuilder}. On the other hand, LLVM required us to include 20 header files in our programs.
  \item We found that writing the IR generators in our test programs took less time with JitBuilder than with LLVM. 
  The most challenging task was writing iterative-fib for LLVM, as this required us to grasp the underlying IR requirements which included: an induction value, a Phi node, several basic blocks for before, during and after the loop, condition values, as well as allocation and store pointers.\footnote{Source code for the LLVM iterative-fibonacci program can be found in the CreateFibFunction within \texttt{src/llvm/iterative-fib/fib.cpp}}.
  \item The in memory objects generated by LLVM MCJIT can contain debug symbols (DWARF format) allowing debugging to take place in GDB 7.0 and higher \cite{llvmDebugJIT}.
\end{itemize}

\subsubsection{Configuration}
While the API of LLVM MCJIT may have an overabundance of controls, it does provide an high level of configuration compared to JitBuilder, including which optimization and analysis passes to run, control over the memory structure of the generated code, control over the object cache, and what level of optimization to generate the code at.
As mentioned, JitBuilder on the other hand is currently locked at the \textit{Warm} optimization level, limiting the number of optimizations performed on the IR.
